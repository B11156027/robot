from openai import OpenAI
from fish_audio_sdk import WebSocketSession, TTSRequest
from pydub import AudioSegment
from pydub.playback import play
import speech_recognition as sr
import io
import threading
import time
import serial
import cv2
import requests
import threading

# Firebase ç›¸é—œå°å…¥
from datetime import datetime
from firebase_admin import db
import firebase_init

# =========== äººè‡‰è¿½è¹¤ï¼‹é¦¬é”æ§åˆ¶ ==========
ESP32_CAM_STREAM = "http://192.168.0.2:81/stream"
SERVO_SERVER_IP = "192.168.0.20"
SERVO_MIN = 1
SERVO_MAX = 179

# è¨­å®š OpenAI å®¢æˆ¶ç«¯
client = OpenAI(api_key="     ")

# å»ºç«‹ TTS WebSocket é€£æ¥
sync_websocket = WebSocketSession("78790b183cab4a4e8d3076ce74056b5c")

# å»ºç«‹èªéŸ³è­˜åˆ¥å™¨
recognizer = sr.Recognizer()
microphone = sr.Microphone()

# å…¨åŸŸè®Šæ•¸æ§åˆ¶èªéŸ³è­˜åˆ¥
listening = False
recognition_thread = None

# Firebase è¨­å®š
device_id = "voice_assistant_001"

arduino = serial.Serial('COM4', 9600, timeout=1)

# å…¨åŸŸè®Šæ•¸ - äº’è­¯æ¨¡å¼æ§åˆ¶
translate_mode = False

def upload_to_firebase(user_input, ai_response, conversation_type="voice"):
    """
    å°‡å°è©±å…§å®¹ä¸Šå‚³åˆ° Firebase
    """
    try:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        conversation_data = {
            "user_input": user_input,
            "ai_response": ai_response,
            "conversation_type": conversation_type,  # "voice" æˆ– "translate"
            "timestamp": timestamp,
            "device_id": device_id,
            "response_length": len(ai_response)
        }
        
        conversation_ref = db.reference(f'ai_conversations/{device_id}')
        conversation_ref.push(conversation_data)
        
        print(f"âœ… å°è©±å·²ä¸Šå‚³åˆ° Firebase: {timestamp}")
        
    except Exception as e:
        print(f"âŒ Firebase ä¸Šå‚³éŒ¯èª¤: {str(e)}")

def upload_system_status(status, message=""):
    """
    ä¸Šå‚³ç³»çµ±ç‹€æ…‹åˆ° Firebase
    """
    try:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        status_data = {
            "status": status,
            "message": message,
            "timestamp": timestamp,
            "device_id": device_id
        }
        
        status_ref = db.reference(f'system_status/{device_id}')
        status_ref.push(status_data)
        
    except Exception as e:
        print(f"âŒ ç³»çµ±ç‹€æ…‹ä¸Šå‚³éŒ¯èª¤: {str(e)}")

def face_tracking_thread(stop_flag):
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    cap = cv2.VideoCapture(ESP32_CAM_STREAM)
    CENTER_DEG = 70
    SENS = 1.10
    ALPHA = 0.35
    SEND_EPS = 2
    SEND_INTERVAL = 0.07
    HEAD_MIN, HEAD_MAX = SERVO_MIN, SERVO_MAX 
    CROP_TOP, CROP_BOT = 0.20, 0.20
    CROP_LEFT, CROP_RIGHT = 0.00, 0.00
    
    if not cap.isOpened():
        print("ä¸²æµç„¡æ³•é–‹å•Ÿï¼Œè«‹æª¢æŸ¥ä¸²æµç¶²å€æˆ–ç¶²è·¯ï¼")
        return
    
    CROP_BOT_RATIO = 0.20
    print("äººè‡‰è¿½è¹¤å•Ÿå‹•ï¼å³æ™‚è¿½è¹¤ä¸­...")
    
    while not stop_flag["stop"]:
        ret, frame = cap.read()
        if not ret:
            continue
        frame = cv2.rotate(frame, cv2.ROTATE_180)
        h, w = frame.shape[:2]
        bottom = int(h * 0.6)
        frame = frame[:bottom, :]
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))
        angle = None
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            face_center_x = x + w // 2
            W = frame.shape[1]

            err = (face_center_x - W/2) / (W/2)
            GAMMA = 1.3
            GAIN  = 2.5
            err_nl = (abs(err) ** GAMMA) * (1 if err >= 0 else -1)

            half_span = (SERVO_MAX - SERVO_MIN) / 2
            angle = int(CENTER_DEG + GAIN * err_nl * half_span)
            angle = max(SERVO_MIN, min(SERVO_MAX, angle))
            break
            
        if angle is not None:
            url = f'http://{SERVO_SERVER_IP}/servo?angle={angle}'
            try:
                requests.get(url, timeout=0.1)
            except Exception as e:
                pass
        cv2.imshow("ESP32-CAM äººè‡‰è¿½è¹¤", frame)
        if cv2.waitKey(1) == 27:
            break
            
    cap.release()
    cv2.destroyAllWindows()
    print("äººè‡‰è¿½è¹¤å·²çµæŸ")

def chat_with_gpt(prompt, conversation_history, model="gpt-3.5-turbo"):
    """
    èˆ‡ ChatGPT é€²è¡Œå°è©±ä¸¦è¿”å›å›æ‡‰æ–‡å­—
    """
    try:
        conversation_history.append({"role": "user", "content": prompt})
        
        response = client.chat.completions.create(
            model=model,
            messages=conversation_history,
            max_tokens=100,
            temperature=0.7
        )
        
        ai_response = response.choices[0].message.content
        conversation_history.append({"role": "assistant", "content": ai_response})
        
        return ai_response
        
    except Exception as e:
        return f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

def translate_text(text, target_language):
    """
    ç¿»è­¯æ–‡å­—åŠŸèƒ½
    """
    try:
        if target_language == "english":
            system_prompt = "You are a translator. Translate the following Chinese text to English. Only return the English translation, no explanations."
        else:
            system_prompt = "You are a translator. Translate the following English text to Traditional Chinese. Only return the Chinese translation, no explanations."
            
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ],
            max_tokens=200,
            temperature=0
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"ç¿»è­¯éŒ¯èª¤: {str(e)}"

def detect_language(text):
    """
    ç°¡å–®çš„èªè¨€æª¢æ¸¬
    """
    chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
    english_chars = sum(1 for char in text if char.isalpha() and char.isascii())
    
    if chinese_chars > english_chars:
        return "chinese"
    else:
        return "english"

def text_to_speech(text, mouth=True):
    try:
        def stream():
            for line in text.split():
                yield line + " "

        tts_request = TTSRequest(
            text="",
            reference_id="075f601e716547829a2397c18ff72317",
            temperature=0.7,
            top_p=0.7,
        )

        audio_data = b""
        for chunk in sync_websocket.tts(tts_request, stream(), backend="speech-1.5"):
            audio_data += chunk
        audio = AudioSegment.from_mp3(io.BytesIO(audio_data))

        # å˜´å·´åŒæ­¥
        playing_flag = [True]
        def mouth_move_thread():
            try:
                arduino.write(b'S')
                while playing_flag[0]:
                    arduino.write(b'S')
                    time.sleep(0.3)
            except Exception as e:
                print(f"[å˜´å·´åŒæ­¥éŒ¯èª¤] {e}")

        t = None
        if mouth:
            t = threading.Thread(target=mouth_move_thread)
            t.start()

        play(audio)

        if mouth:
            playing_flag[0] = False
            arduino.write(b'E')
            if t:
                t.join()

    except Exception as e:
        print(f"TTS éŒ¯èª¤: {str(e)}")

def speech_to_text():
    """
    èªéŸ³è½‰æ–‡å­—
    """
    recognizer.dynamic_energy_threshold = True
    recognizer.pause_threshold = 2
    recognizer.non_speaking_duration = 2.0
    
    while True:
        try:
            print("ğŸ¤ è«‹é–‹å§‹èªªè©±...ï¼ˆåœé “1.5ç§’è‡ªå‹•çµæŸï¼‰")
            with microphone as source:
                recognizer.adjust_for_ambient_noise(source, duration=0.5)
                audio = recognizer.listen(source, timeout=None)
            text = recognizer.recognize_google(audio, language="zh-TW")
            return text
        except sr.UnknownValueError:
            continue
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue

def continuous_voice_recognition(conversation_history):
    """
    æŒçºŒèªéŸ³è­˜åˆ¥åŠŸèƒ½
    """
    global listening, translate_mode
    
    print("\nğŸ¤ èªéŸ³è­˜åˆ¥å·²å•Ÿå‹•ï¼")
    print("ğŸ’¡ èªéŸ³æŒ‡ä»¤ï¼š")
    print("   - èªª 'äº’è­¯æ¨¡å¼' é–‹å•Ÿä¸­è‹±äº’è­¯")
    print("   - èªª 'èŠå¤©æ¨¡å¼' é—œé–‰äº’è­¯ï¼Œå›åˆ°æ­£å¸¸å°è©±")
    print("   - èªª 'çµæŸå°è©±' æˆ– 'å†è¦‹' å¯çµæŸç¨‹å¼")
    print("   - èªª 'æ¸…é™¤è¨˜æ†¶' å¯æ¸…é™¤å°è©±è¨˜éŒ„")
    print("   - èªª 'æŸ¥çœ‹è¨˜éŒ„' å¯é¡¯ç¤ºå°è©±æ­·å²\n")
    
    upload_system_status("voice_mode", "èªéŸ³æ¨¡å¼å•Ÿå‹•")
    
    while listening:
        try:
            user_input = speech_to_text()
            
            if user_input is None:
                continue
            
            # æª¢æŸ¥ç‰¹æ®ŠæŒ‡ä»¤
            if any(cmd in user_input for cmd in ['çµæŸå°è©±', 'å†è¦‹', 'æ°æ°']):
                print("ğŸ‘‹ å†è¦‹ï¼")
                farewell_msg = "å†è¦‹å•¦ï¼"
                text_to_speech(farewell_msg)
                upload_to_firebase(user_input, farewell_msg, "voice")
                upload_system_status("stopped", "ç”¨æˆ¶çµæŸå°è©±")
                return "quit"
                
            elif any(cmd in user_input for cmd in ['äº’è­¯æ¨¡å¼', 'ç¿»è­¯æ¨¡å¼', 'é–‹å•Ÿç¿»è­¯']):
                translate_mode = True
                status_msg = "å·²é–‹å•Ÿäº’è­¯æ¨¡å¼"
                print(f"ğŸ”„ {status_msg}")
                text_to_speech(status_msg)
                upload_to_firebase(user_input, status_msg, "voice")
                continue
                
            elif any(cmd in user_input for cmd in ['èŠå¤©æ¨¡å¼', 'é—œé–‰ç¿»è­¯', 'åœæ­¢ç¿»è­¯']):
                translate_mode = False
                status_msg = "å·²é—œé–‰äº’è­¯æ¨¡å¼"
                print(f"ğŸ”„ {status_msg}")
                text_to_speech(status_msg)
                upload_to_firebase(user_input, status_msg, "voice")
                continue
                
            elif any(cmd in user_input for cmd in ['æ¸…é™¤è¨˜æ†¶', 'æ¸…é™¤å°è©±', 'é‡æ–°é–‹å§‹']):
                system_messages = [msg for msg in conversation_history if msg["role"] == "system"]
                conversation_history.clear()
                conversation_history.extend(system_messages)
                print("âœ… å°è©±è¨˜æ†¶å·²æ¸…é™¤ï¼\n")
                clear_msg = "è¨˜æ†¶å·²æ¸…é™¤"
                text_to_speech(clear_msg)
                upload_to_firebase(user_input, clear_msg, "voice")
                continue
                
            elif any(cmd in user_input for cmd in ['æŸ¥çœ‹è¨˜éŒ„', 'é¡¯ç¤ºè¨˜éŒ„', 'å°è©±è¨˜éŒ„']):
                print("\n=== å°è©±è¨˜éŒ„ ===")
                for msg in conversation_history:
                    if msg["role"] == "system":
                        print(f"[ç³»çµ±] {msg['content'][:50]}...")
                    elif msg["role"] == "user":
                        print(f"[ä½ ] {msg['content']}")
                    elif msg["role"] == "assistant":
                        print(f"[AI] {msg['content']}")
                print("==================\n")
                history_msg = "è¨˜éŒ„å·²é¡¯ç¤º"
                text_to_speech(history_msg)
                upload_to_firebase(user_input, history_msg, "voice")
                continue
            
            # æ­£å¸¸å°è©±è™•ç†
            print(f"ğŸ—£ï¸ ä½ èªª: {user_input}")
            
            if translate_mode:
                # äº’è­¯æ¨¡å¼
                detected_lang = detect_language(user_input)
                print(f"ğŸ” æª¢æ¸¬èªè¨€: {'ä¸­æ–‡' if detected_lang == 'chinese' else 'è‹±æ–‡'}")
                
                if detected_lang == "chinese":
                    # ä¸­æ–‡ â†’ è‹±æ–‡
                    translation = translate_text(user_input, "english")
                    print(f"ğŸ“ è‹±æ–‡ç¿»è­¯: {translation}")
                    response_text = translation
                    upload_to_firebase(user_input, f"[ä¸­â†’è‹±] {translation}", "translate")
                else:
                    # è‹±æ–‡ â†’ ä¸­æ–‡
                    translation = translate_text(user_input, "chinese")
                    print(f"ğŸ“ ä¸­æ–‡ç¿»è­¯: {translation}")
                    response_text = translation
                    upload_to_firebase(user_input, f"[è‹±â†’ä¸­] {translation}", "translate")
                
                print("ğŸ”Š æ­£åœ¨æ’­æ”¾ç¿»è­¯çµæœ...")
                text_to_speech(response_text)
                print("âœ… ç¿»è­¯æ’­æ”¾å®Œæˆï¼\n")
                
            else:
                # æ­£å¸¸èŠå¤©æ¨¡å¼
                gpt_response = chat_with_gpt(user_input, conversation_history)
                print(f"ğŸ¤– AIå›ç­”: {gpt_response}\n")
                
                upload_to_firebase(user_input, gpt_response, "voice")
                
                print("ğŸ”Š æ­£åœ¨æ’­æ”¾èªéŸ³...")
                text_to_speech(gpt_response)
                print("âœ… èªéŸ³æ’­æ”¾å®Œæˆï¼\n")
            
        except KeyboardInterrupt:
            print("\nâš ï¸ èªéŸ³è­˜åˆ¥è¢«ä¸­æ–·")
            upload_system_status("interrupted", "èªéŸ³è­˜åˆ¥è¢«ä¸­æ–·")
            break
        except Exception as e:
            print(f"âŒ èªéŸ³è­˜åˆ¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            upload_system_status("error", f"èªéŸ³è­˜åˆ¥éŒ¯èª¤: {str(e)}")
            continue
    
    return None

def get_user_mode():
    """
    è®“ç”¨æˆ¶é¸æ“‡æ¨¡å¼
    """
    print("\nğŸ“ è«‹é¸æ“‡æ¨¡å¼ï¼š")
    print("1. äº’è­¯æ¨¡å¼ï¼ˆä¸­è‹±æ–‡äº’è­¯ï¼‰")
    print("2. èªéŸ³èŠå¤©æ¨¡å¼ï¼ˆAIå°è©±ï¼‰")
    
    while True:
        choice = input("è«‹é¸æ“‡ (1-2): ").strip()
        if choice in ['1', '2']:
            return choice
        print("âŒ ç„¡æ•ˆé¸æ“‡ï¼Œè«‹è¼¸å…¥ 1 æˆ– 2")

def chat_and_speak():
    """
    ç´”èªéŸ³åŠ©æ‰‹ä¸»å‡½æ•¸
    """
    global listening, translate_mode
    
    print("=== ChatGPT ç´”èªéŸ³åŠ©æ‰‹ ===")
    print("ğŸ¤ ç´”èªéŸ³æ“ä½œï¼Œæ”¯æ´ä¸­è‹±äº’è­¯å’ŒAIå°è©±")
    print("ğŸ“Š Firebase æ•´åˆï¼šæ‰€æœ‰å°è©±éƒ½æœƒä¸Šå‚³åˆ°é›²ç«¯")
    
    upload_system_status("started", "ç´”èªéŸ³åŠ©æ‰‹å•Ÿå‹•")
    
    # é¸æ“‡åˆå§‹æ¨¡å¼
    initial_mode = get_user_mode()
    
    if initial_mode == "1":
        translate_mode = True
        print("ğŸ”„ å·²è¨­å®šç‚ºäº’è­¯æ¨¡å¼")
        print("   ğŸ‡¨ğŸ‡³ èªªä¸­æ–‡ â†’ ç¿»è­¯æˆè‹±æ–‡")
        print("   ğŸ‡ºğŸ‡¸ èªªè‹±æ–‡ â†’ ç¿»è­¯æˆä¸­æ–‡\n")
    else:
        translate_mode = False
        print("ğŸ’¬ å·²è¨­å®šç‚ºèªéŸ³èŠå¤©æ¨¡å¼")
        print("   ğŸ¤– èˆ‡AIé€²è¡Œæ­£å¸¸å°è©±\n")
    
    # ç³»çµ±æç¤ºè©
    conversation_history = []
    system_prompt = "ä½ æ˜¯ä¸€å€‹å‹å–„ä¸”æ¨‚æ–¼åŠ©äººçš„ AI åŠ©æ‰‹ï¼Œå›ç­”å•é¡Œæ™‚è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªæ°£è¦è¦ªåˆ‡è‡ªç„¶ã€‚è«‹å°‡æ¯æ¬¡å›ç­”æ§åˆ¶åœ¨30å€‹ä¸­æ–‡å­—ä»¥å…§ï¼Œç°¡æ½”æ˜ç­ã€‚"
    conversation_history.append({"role": "system", "content": system_prompt})
    
    print("âœ… ç´”èªéŸ³æ“ä½œæ¨¡å¼")
    print("âœ… æ”¯æ´ä¸­è‹±äº’è­¯")
    print("âœ… æ”¯æ´AIå°è©±")
    print("âœ… Firebase é›²ç«¯è¨˜éŒ„")
    print("âœ… äººè‡‰è¿½è¹¤åŠŸèƒ½\n")
    
    # é–‹å§‹èªéŸ³è­˜åˆ¥
    listening = True
    continuous_voice_recognition(conversation_history)

# åŸ·è¡Œç¨‹å¼
if __name__ == "__main__":
    try:
        # å•Ÿå‹•äººè‡‰è¿½è¹¤ç·šç¨‹
        stop_flag = {"stop": False}
        tracking_thread = threading.Thread(target=face_tracking_thread, args=(stop_flag,))
        tracking_thread.daemon = True
        tracking_thread.start()

        # æª¢æŸ¥éº¥å…‹é¢¨å¯ç”¨æ€§
        print("ğŸ”§ æ­£åœ¨æª¢æŸ¥éº¥å…‹é¢¨...")
        with sr.Microphone() as source:
            pass
        print("âœ… éº¥å…‹é¢¨æª¢æŸ¥é€šéï¼\n")
        
        # å•Ÿå‹•ä¸»ç¨‹å¼
        chat_and_speak()
        
    except Exception as e:
        print(f"âŒ éº¥å…‹é¢¨åˆå§‹åŒ–å¤±æ•—: {e}")
        upload_system_status("error", f"éº¥å…‹é¢¨åˆå§‹åŒ–å¤±æ•—: {str(e)}")
        print("âš ï¸ ç„¡æ³•å•Ÿå‹•ç´”èªéŸ³æ¨¡å¼")
        
    finally:
        # ç•¶ä¸»ç¨‹å¼çµæŸæ™‚çµ‚æ­¢äººè‡‰è¿½è¹¤
        stop_flag["stop"] = True
        if 'tracking_thread' in locals():
            tracking_thread.join()
        upload_system_status("shutdown", "ç¨‹å¼æ­£å¸¸é—œé–‰")